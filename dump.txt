
===== ./Dockerfile =====
# NetOpsTool — Dockerfile
FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

WORKDIR /app

# System deps kept tiny
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates curl \
 && rm -rf /var/lib/apt/lists/*

# App deps
COPY requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt

# App source (package + assets)
COPY netops /app/netops
COPY templates /app/templates
COPY static /app/static
COPY alembic /app/alembic
COPY alembic.ini /app/alembic.ini
COPY entrypoint.sh /app/entrypoint.sh
COPY README.md /app/README.md
RUN chmod +x /app/entrypoint.sh

# Data directory (sqlite) created at runtime via compose bind-mount
RUN mkdir -p /app/data && chmod 755 /app/data

# Secrets live under /run/secrets (volume in compose)
RUN mkdir -p /run/secrets

# Healthcheck (lightweight)
HEALTHCHECK --interval=30s --timeout=3s --retries=3 CMD curl -fsS http://127.0.0.1:5250/healthz || exit 1

EXPOSE 5250

ENTRYPOINT ["/app/entrypoint.sh"]
CMD ["waitress-serve", "--port=5250", "netops.app:app"]

===== ./README.md =====
# README.md

# NetOpsTool

Server-side aggregator + viewer for AirOps feeder snapshots.

## Quick Start

```bash
# 1) build and run (port 5250)
docker compose up --build -d

# 2) create a station to allow feeder login
docker compose exec netops python -m netops.cli add-station STATION-01 supersecret

# 3) (optional) upsert an airport (ingest also auto-upserts default_origin)
curl -X POST http://localhost:5250/api/airports \
  -H 'Content-Type: application/json' \
  -H "X-Admin-Password: ${ADMIN_PASSWORD:-}" \
  -d '{"code":"KSEA","lat":47.4502,"lon":-122.3088}'

# Health checks
curl -fsS http://localhost:5250/healthz
curl -fsS http://localhost:5250/readyz

# Login + Ingest (example)
TOKEN=$(curl -s http://localhost:5250/api/login \
  -H 'Content-Type: application/json' \
  -d '{"station":"STATION-01","password":"supersecret"}' | jq -r .token)

curl -s http://localhost:5250/api/ingest \
  -H "Authorization: Bearer ${TOKEN}" \
  -H 'Content-Type: application/json' \
  -d '{
        "station":"STATION-01",
        "generated_at":"2025-08-24T00:00:00Z",
        "default_origin":"KSEA",
        "origin_coords":{"lat":47.4502,"lon":-122.3088},
        "flows":[{"origin":"KSEA","dest":"KPDX","direction":"outbound","legs":3,"weight_lbs":12000.5}]
      }'

===== ./alembic.ini =====
# alembic.ini
[alembic]
script_location = alembic
sqlalchemy.url = sqlite:////data/netops.db

[loggers]
keys = root,sqlalchemy,alembic
[handlers]
keys = console
[formatters]
keys = generic
[logger_root]
level = WARN
handlers = console
[logger_sqlalchemy]
level = WARN
handlers = console
qualname = sqlalchemy.engine
[logger_alembic]
level = INFO
handlers = console
qualname = alembic
[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = INFO
formatter = generic
[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s

===== ./alembic/env.py =====
# alembic/env.py
from __future__ import annotations
from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
import os, sys

# this is the Alembic Config object
config = context.config

# Interpret the config file for Python logging.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from netops.db import Base  # noqa

target_metadata = Base.metadata

def run_migrations_offline():
    context.configure(
        url=config.get_main_option("sqlalchemy.url"),
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )
    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online():
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata)
        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

===== ./alembic/versions/20250824_000001_init.py =====
# alembic/versions/20250824_000001_init.py
"""initial schema

Revision ID: 000001_init
Revises:
Create Date: 2025-08-24 00:00:01
"""
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic.
revision = '000001_init'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    op.create_table('stations',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('name', sa.String(128), nullable=False, unique=True),
        sa.Column('password_hash', sa.String(256), nullable=False),
        sa.Column('token_salt', sa.String(64), nullable=False, server_default=''),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('last_seen_at', sa.DateTime(), nullable=True),
        sa.Column('last_default_origin', sa.String(8), nullable=True),
        sa.Column('last_origin_lat', sa.Float(), nullable=True),
        sa.Column('last_origin_lon', sa.Float(), nullable=True),
    )
    op.create_table('snapshots',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('station_id', sa.Integer(), sa.ForeignKey('stations.id'), nullable=False),
        sa.Column('generated_at', sa.DateTime(), nullable=False),
        sa.Column('window_hours', sa.Integer(), nullable=False, server_default='24'),
        sa.Column('inventory_last_update', sa.String(64), nullable=True),
        sa.UniqueConstraint('station_id','generated_at', name='uq_snap_station_gen')
    )
    op.create_index('ix_snapshot_generated_at', 'snapshots', ['generated_at'])

    op.create_table('flows',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('snapshot_id', sa.Integer(), sa.ForeignKey('snapshots.id'), nullable=False),
        sa.Column('origin', sa.String(8), nullable=False),
        sa.Column('dest', sa.String(8), nullable=False),
        sa.Column('direction', sa.String(10), nullable=False),
        sa.Column('legs', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('weight_lbs', sa.Float(), nullable=False, server_default='0'),
    )
    op.create_index('ix_flows_route_dir', 'flows', ['origin','dest','direction'])
    op.create_index('ix_flows_snapshot', 'flows', ['snapshot_id'])

    op.create_table('flights',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('station_id', sa.Integer(), sa.ForeignKey('stations.id'), nullable=False),
        sa.Column('aoct_flight_id', sa.Integer(), nullable=True),
        sa.Column('flight_code', sa.String(32), nullable=True, unique=True),
        sa.Column('tail', sa.String(16), nullable=True),
        sa.Column('direction', sa.String(10), nullable=True),
        sa.Column('origin', sa.String(8), nullable=True),
        sa.Column('dest', sa.String(8), nullable=True),
        sa.Column('cargo_type', sa.String(128), nullable=True),
        sa.Column('cargo_weight_lbs', sa.Float(), nullable=True),
        sa.Column('takeoff_hhmm', sa.String(4), nullable=True),
        sa.Column('eta_hhmm', sa.String(4), nullable=True),
        sa.Column('is_ramp_entry', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('complete', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('remarks', sa.Text(), nullable=True),
        sa.Column('first_seen_at', sa.DateTime(), nullable=False),
        sa.Column('last_seen_at', sa.DateTime(), nullable=False),
    )
    op.create_index('ix_flights_origin_dest_dir', 'flights', ['origin','dest','direction'])
    op.create_index('ix_flights_complete_seen', 'flights', ['complete','last_seen_at'])
    op.create_index('ix_flights_station_aoct', 'flights', ['station_id','aoct_flight_id'])

    op.create_table('ingest_log',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('station_id', sa.Integer(), sa.ForeignKey('stations.id'), nullable=False),
        sa.Column('received_at', sa.DateTime(), nullable=False),
        sa.Column('status', sa.String(16), nullable=False),
        sa.Column('error', sa.Text(), nullable=True),
        sa.Column('raw', sa.Text(), nullable=True),
    )

    op.create_table('airports',
        sa.Column('code', sa.String(8), primary_key=True),
        sa.Column('lat', sa.Float(), nullable=False),
        sa.Column('lon', sa.Float(), nullable=False),
    )
    op.create_index('ix_airports_code', 'airports', ['code'])

def downgrade():
    op.drop_table('airports')
    op.drop_table('ingest_log')
    op.drop_index('ix_flights_station_aoct', table_name='flights')
    op.drop_index('ix_flights_complete_seen', table_name='flights')
    op.drop_index('ix_flights_origin_dest_dir', table_name='flights')
    op.drop_table('flights')
    op.drop_index('ix_flows_snapshot', table_name='flows')
    op.drop_index('ix_flows_route_dir', table_name='flows')
    op.drop_table('flows')
    op.drop_index('ix_snapshot_generated_at', table_name='snapshots')
    op.drop_table('snapshots')
    op.drop_table('stations')

===== ./docker-compose.yml =====
version: "3.8"

services:
  netops:
    build: .
    container_name: netops_tool
    ports:
      - "5250:5250"
    restart: unless-stopped
    volumes:
      - ./data:/app/data
      - flask_secret:/run/secrets
    environment:
      - LOG_LEVEL=INFO

volumes:
  flask_secret:

===== ./dump.txt =====

===== ./Dockerfile =====
# NetOpsTool — Dockerfile
FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

WORKDIR /app

# System deps kept tiny
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates curl \
 && rm -rf /var/lib/apt/lists/*

# App deps
COPY requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt

# App source (package + assets)
COPY netops /app/netops
COPY templates /app/templates
COPY static /app/static
COPY alembic /app/alembic
COPY alembic.ini /app/alembic.ini
COPY entrypoint.sh /app/entrypoint.sh
COPY README.md /app/README.md
RUN chmod +x /app/entrypoint.sh

# Data directory (sqlite) created at runtime via compose bind-mount
RUN mkdir -p /app/data && chmod 755 /app/data

# Secrets live under /run/secrets (volume in compose)
RUN mkdir -p /run/secrets

# Healthcheck (lightweight)
HEALTHCHECK --interval=30s --timeout=3s --retries=3 CMD curl -fsS http://127.0.0.1:5250/healthz || exit 1

EXPOSE 5250

ENTRYPOINT ["/app/entrypoint.sh"]
CMD ["waitress-serve", "--port=5250", "netops.app:app"]

===== ./README.md =====
# README.md

# NetOpsTool

Server-side aggregator + viewer for AirOps feeder snapshots.

## Quick Start

```bash
# 1) build and run (port 5250)
docker compose up --build -d

# 2) create a station to allow feeder login
docker compose exec netops python -m netops.cli add-station STATION-01 supersecret

# 3) (optional) upsert an airport (ingest also auto-upserts default_origin)
curl -X POST http://localhost:5250/api/airports \
  -H 'Content-Type: application/json' \
  -H "X-Admin-Password: ${ADMIN_PASSWORD:-}" \
  -d '{"code":"KSEA","lat":47.4502,"lon":-122.3088}'

# Health checks
curl -fsS http://localhost:5250/healthz
curl -fsS http://localhost:5250/readyz

# Login + Ingest (example)
TOKEN=$(curl -s http://localhost:5250/api/login \
  -H 'Content-Type: application/json' \
  -d '{"station":"STATION-01","password":"supersecret"}' | jq -r .token)

curl -s http://localhost:5250/api/ingest \
  -H "Authorization: Bearer ${TOKEN}" \
  -H 'Content-Type: application/json' \
  -d '{
        "station":"STATION-01",
        "generated_at":"2025-08-24T00:00:00Z",
        "default_origin":"KSEA",
        "origin_coords":{"lat":47.4502,"lon":-122.3088},
        "flows":[{"origin":"KSEA","dest":"KPDX","direction":"outbound","legs":3,"weight_lbs":12000.5}]
      }'

===== ./alembic.ini =====
# alembic.ini
[alembic]
script_location = alembic
sqlalchemy.url = sqlite:////data/netops.db

[loggers]
keys = root,sqlalchemy,alembic
[handlers]
keys = console
[formatters]
keys = generic
[logger_root]
level = WARN
handlers = console
[logger_sqlalchemy]
level = WARN
handlers = console
qualname = sqlalchemy.engine
[logger_alembic]
level = INFO
handlers = console
qualname = alembic
[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = INFO
formatter = generic
[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s

===== ./alembic/env.py =====
# alembic/env.py
from __future__ import annotations
from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
import os, sys

# this is the Alembic Config object
config = context.config

# Interpret the config file for Python logging.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from netops.db import Base  # noqa

target_metadata = Base.metadata

def run_migrations_offline():
    context.configure(
        url=config.get_main_option("sqlalchemy.url"),
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )
    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online():
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata)
        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

===== ./alembic/versions/20250824_000001_init.py =====
# alembic/versions/20250824_000001_init.py
"""initial schema

Revision ID: 000001_init
Revises:
Create Date: 2025-08-24 00:00:01
"""
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic.
revision = '000001_init'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    op.create_table('stations',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('name', sa.String(128), nullable=False, unique=True),
        sa.Column('password_hash', sa.String(256), nullable=False),
        sa.Column('token_salt', sa.String(64), nullable=False, server_default=''),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('last_seen_at', sa.DateTime(), nullable=True),
        sa.Column('last_default_origin', sa.String(8), nullable=True),
        sa.Column('last_origin_lat', sa.Float(), nullable=True),
        sa.Column('last_origin_lon', sa.Float(), nullable=True),
    )
    op.create_table('snapshots',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('station_id', sa.Integer(), sa.ForeignKey('stations.id'), nullable=False),
        sa.Column('generated_at', sa.DateTime(), nullable=False),
        sa.Column('window_hours', sa.Integer(), nullable=False, server_default='24'),
        sa.Column('inventory_last_update', sa.String(64), nullable=True),
        sa.UniqueConstraint('station_id','generated_at', name='uq_snap_station_gen')
    )
    op.create_index('ix_snapshot_generated_at', 'snapshots', ['generated_at'])

    op.create_table('flows',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('snapshot_id', sa.Integer(), sa.ForeignKey('snapshots.id'), nullable=False),
        sa.Column('origin', sa.String(8), nullable=False),
        sa.Column('dest', sa.String(8), nullable=False),
        sa.Column('direction', sa.String(10), nullable=False),
        sa.Column('legs', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('weight_lbs', sa.Float(), nullable=False, server_default='0'),
    )
    op.create_index('ix_flows_route_dir', 'flows', ['origin','dest','direction'])
    op.create_index('ix_flows_snapshot', 'flows', ['snapshot_id'])

    op.create_table('flights',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('station_id', sa.Integer(), sa.ForeignKey('stations.id'), nullable=False),
        sa.Column('aoct_flight_id', sa.Integer(), nullable=True),
        sa.Column('flight_code', sa.String(32), nullable=True, unique=True),
        sa.Column('tail', sa.String(16), nullable=True),
        sa.Column('direction', sa.String(10), nullable=True),
        sa.Column('origin', sa.String(8), nullable=True),
        sa.Column('dest', sa.String(8), nullable=True),
        sa.Column('cargo_type', sa.String(128), nullable=True),
        sa.Column('cargo_weight_lbs', sa.Float(), nullable=True),
        sa.Column('takeoff_hhmm', sa.String(4), nullable=True),
        sa.Column('eta_hhmm', sa.String(4), nullable=True),
        sa.Column('is_ramp_entry', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('complete', sa.Integer(), nullable=False, server_default='0'),
        sa.Column('remarks', sa.Text(), nullable=True),
        sa.Column('first_seen_at', sa.DateTime(), nullable=False),
        sa.Column('last_seen_at', sa.DateTime(), nullable=False),
    )
    op.create_index('ix_flights_origin_dest_dir', 'flights', ['origin','dest','direction'])
    op.create_index('ix_flights_complete_seen', 'flights', ['complete','last_seen_at'])
    op.create_index('ix_flights_station_aoct', 'flights', ['station_id','aoct_flight_id'])

    op.create_table('ingest_log',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('station_id', sa.Integer(), sa.ForeignKey('stations.id'), nullable=False),
        sa.Column('received_at', sa.DateTime(), nullable=False),
        sa.Column('status', sa.String(16), nullable=False),
        sa.Column('error', sa.Text(), nullable=True),
        sa.Column('raw', sa.Text(), nullable=True),
    )

    op.create_table('airports',
        sa.Column('code', sa.String(8), primary_key=True),
        sa.Column('lat', sa.Float(), nullable=False),
        sa.Column('lon', sa.Float(), nullable=False),
    )
    op.create_index('ix_airports_code', 'airports', ['code'])

def downgrade():
    op.drop_table('airports')
    op.drop_table('ingest_log')
    op.drop_index('ix_flights_station_aoct', table_name='flights')
    op.drop_index('ix_flights_complete_seen', table_name='flights')
    op.drop_index('ix_flights_origin_dest_dir', table_name='flights')
    op.drop_table('flights')
    op.drop_index('ix_flows_snapshot', table_name='flows')
    op.drop_index('ix_flows_route_dir', table_name='flows')
    op.drop_table('flows')
    op.drop_index('ix_snapshot_generated_at', table_name='snapshots')
    op.drop_table('snapshots')
    op.drop_table('stations')

===== ./docker-compose.yml =====
version: "3.8"

services:
  netops:
    build: .
    container_name: netops_tool
    ports:
      - "5250:5250"
    restart: unless-stopped
    volumes:
      - ./data:/app/data
      - flask_secret:/run/secrets
    environment:
      - LOG_LEVEL=INFO

volumes:
  flask_secret:

===== ./dump.txt =====

===== ./entrypoint.sh =====
#!/usr/bin/env bash
set -euo pipefail

SECRET_DIR=/run/secrets
FLASK_SECRET_FILE="${SECRET_DIR}/flask_secret"
INGEST_SECRET_FILE="${SECRET_DIR}/netops_ingest_password"

# Generate Flask SECRET_KEY if missing (same pattern as AirOpsTool)
if [ ! -f "${FLASK_SECRET_FILE}" ]; then
  echo "Generating Flask secret…"
  mkdir -p "${SECRET_DIR}"
  umask 077
  openssl rand -hex 32 > "${FLASK_SECRET_FILE}"
fi

exec "$@"

===== ./netops/__init__.py =====
"""
NetOpsTool package.
Run via Waitress: `waitress-serve --port=8080 netops.app:app`
"""

===== ./netops/app.py =====
# netops/app.py
from __future__ import annotations
from flask import Flask
from flask_cors import CORS
from .config import config
from .db import init_db
from .routes.api import api
from .routes.pages import pages

app = Flask(__name__, static_folder="../static", template_folder="../templates")
app.config.update(SECRET_KEY=config.SECRET_KEY, ENV=config.ENV, DEBUG=config.DEBUG)

# Init DB (bootstrap for first run)
init_db()

# Rate limiter: use the limiter object defined in the api module and bind it here
from .routes import api as api_mod  # noqa: E402
api_mod.limiter.init_app(app)

# CORS (optional)
if config.ENABLE_CORS:
    CORS(app, resources={r"/api/*": {"origins": "*"}})

# Blueprints
app.register_blueprint(api)
app.register_blueprint(pages)

# Health
@app.get("/healthz")
def healthz():
    return {"ok": True}

@app.get("/readyz")
def readyz():
    return {"ok": True}

===== ./netops/auth.py =====
# netops/auth.py
from __future__ import annotations
import jwt
from datetime import datetime, timezone
from argon2 import PasswordHasher
from argon2.exceptions import VerifyMismatchError
from flask import request, abort
from typing import Optional, Tuple
from .config import config

_ph = PasswordHasher()

def hash_password(pw: str) -> str:
    return _ph.hash(pw)

def verify_password(phash: str, pw: str) -> bool:
    try:
        return _ph.verify(phash, pw)
    except VerifyMismatchError:
        return False

def issue_token(station_id: int, token_salt: str) -> str:
    now = datetime.now(timezone.utc)
    payload = {
        "sub": station_id,
        "iat": int(now.timestamp()),
        "exp": int((now + config.TOKEN_TTL).timestamp()),
        "salt": token_salt,
    }
    return jwt.encode(payload, config.NETOPS_JWT_SECRET, algorithm="HS256")

def _bearer_token() -> Optional[str]:
    auth = request.headers.get("Authorization", "")
    if not auth.startswith("Bearer "):
        return None
    return auth.split(" ", 1)[1].strip()

def require_bearer() -> Tuple[int, dict]:
    token = _bearer_token()
    if not token:
        abort(401, description="Missing bearer token")
    try:
        payload = jwt.decode(token, config.NETOPS_JWT_SECRET, algorithms=["HS256"])
    except jwt.PyJWTError:
        abort(401, description="Invalid token")
    return int(payload["sub"]), payload

===== ./netops/cli.py =====
# netops/cli.py
from __future__ import annotations
import argparse
import secrets
from .db import SessionLocal, init_db
from .models import Station
from .auth import hash_password

def add_station(name: str, password: str):
    with SessionLocal() as s:
        exists = s.query(Station).filter(Station.name == name).first()
        if exists:
            raise SystemExit(f"Station '{name}' already exists.")
        st = Station(
            name=name,
            password_hash=hash_password(password),
            token_salt=secrets.token_hex(8)
        )
        s.add(st)
        s.commit()
        print(f"Added station: {name}")

def reset_station_password(name: str, password: str):
    with SessionLocal() as s:
        st = s.query(Station).filter(Station.name == name).first()
        if not st:
            raise SystemExit(f"Station '{name}' not found.")
        st.password_hash = hash_password(password)
        st.token_salt = secrets.token_hex(8)  # invalidate existing tokens
        s.commit()
        print(f"Password reset for station: {name}")

def main():
    parser = argparse.ArgumentParser(prog="netops")
    sub = parser.add_subparsers(dest="cmd", required=True)
    a = sub.add_parser("add-station")
    a.add_argument("name")
    a.add_argument("password")
    r = sub.add_parser("reset-station-password")
    r.add_argument("name")
    r.add_argument("password")
    args = parser.parse_args()

    init_db()

    if args.cmd == "add-station":
        add_station(args.name, args.password)
    elif args.cmd == "reset-station-password":
        reset_station_password(args.name, args.password)

if __name__ == "__main__":
    main()

===== ./netops/config.py =====
# netops/config.py
from __future__ import annotations
import os
from datetime import timedelta

class Config:
    # Flask
    # Prefer Docker secret -> env (FLASK_SECRET or SECRET_KEY) -> dev fallback
    @staticmethod
    def _read_secret_file(path: str) -> str | None:
        try:
            if os.path.exists(path):
                with open(path, "r") as f:
                    return f.read().strip()
        except Exception:
            pass
        return None

    SECRET_KEY = (
        _read_secret_file.__func__("/run/secrets/flask_secret")
        or os.getenv("FLASK_SECRET")
        or os.getenv("SECRET_KEY")
        or "dev-secret-change-me"
    )
    ENV = os.getenv("FLASK_ENV", "production")
    DEBUG = ENV != "production"

    # DB
    DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:////data/netops.db")

    # Auth
    NETOPS_JWT_SECRET = os.getenv("NETOPS_JWT_SECRET", "dev-jwt-secret-change-me")
    TOKEN_TTL = timedelta(hours=float(os.getenv("TOKEN_TTL_HOURS", "24")))
    ADMIN_PASSWORD = os.getenv("ADMIN_PASSWORD", "")  # optional UI gate

    # Rate Limits
    LOGIN_RATE = os.getenv("LOGIN_RATE", "20 per hour")
    INGEST_RATE = os.getenv("INGEST_RATE", "600 per hour")

    # CORS (disabled by default)
    ENABLE_CORS = os.getenv("ENABLE_CORS", "0") == "1"

config = Config()

===== ./netops/db.py =====
# netops/db.py
from __future__ import annotations
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, scoped_session, declarative_base
from .config import config

engine = create_engine(config.DATABASE_URL, future=True, pool_pre_ping=True)
SessionLocal = scoped_session(sessionmaker(bind=engine, autoflush=False, autocommit=False, future=True))
Base = declarative_base()

def init_db():
    # Fallback bootstrap so the app is usable even before Alembic runs.
    from . import models  # noqa: F401
    Base.metadata.create_all(bind=engine)

===== ./netops/models.py =====
# netops/models.py
from __future__ import annotations
from datetime import datetime
from sqlalchemy import (
    Column, Integer, String, DateTime, Float, Text, ForeignKey, UniqueConstraint, Index
)
from sqlalchemy.orm import relationship
from .db import Base

class Station(Base):
    __tablename__ = "stations"
    id = Column(Integer, primary_key=True)
    name = Column(String(128), unique=True, nullable=False, index=True)
    password_hash = Column(String(256), nullable=False)
    token_salt = Column(String(64), nullable=False, default="")
    created_at = Column(DateTime, nullable=False, default=datetime.utcnow)
    last_seen_at = Column(DateTime, nullable=True)
    last_default_origin = Column(String(8), nullable=True)
    last_origin_lat = Column(Float, nullable=True)
    last_origin_lon = Column(Float, nullable=True)

    snapshots = relationship("Snapshot", back_populates="station", cascade="all,delete-orphan")
    flights = relationship("Flight", back_populates="station", cascade="all,delete-orphan")

class Snapshot(Base):
    __tablename__ = "snapshots"
    id = Column(Integer, primary_key=True)
    station_id = Column(Integer, ForeignKey("stations.id"), nullable=False)
    generated_at = Column(DateTime, nullable=False)
    window_hours = Column(Integer, nullable=False, default=24)
    inventory_last_update = Column(String(64), nullable=True)

    station = relationship("Station", back_populates="snapshots")
    flows = relationship("Flow", back_populates="snapshot", cascade="all,delete-orphan")

    __table_args__ = (
        UniqueConstraint("station_id", "generated_at", name="uq_snap_station_gen"),
        Index("ix_snapshot_generated_at", "generated_at"),
    )

class Flow(Base):
    __tablename__ = "flows"
    id = Column(Integer, primary_key=True)
    snapshot_id = Column(Integer, ForeignKey("snapshots.id"), nullable=False)
    origin = Column(String(8), nullable=False)
    dest = Column(String(8), nullable=False)
    direction = Column(String(10), nullable=False)  # inbound|outbound
    legs = Column(Integer, nullable=False, default=0)
    weight_lbs = Column(Float, nullable=False, default=0.0)

    snapshot = relationship("Snapshot", back_populates="flows")
    __table_args__ = (
        Index("ix_flows_route_dir", "origin", "dest", "direction"),
        Index("ix_flows_snapshot", "snapshot_id"),
    )

class Flight(Base):
    __tablename__ = "flights"
    id = Column(Integer, primary_key=True)
    station_id = Column(Integer, ForeignKey("stations.id"), nullable=False)
    aoct_flight_id = Column(Integer, nullable=True)
    flight_code = Column(String(32), nullable=True, unique=True)
    tail = Column(String(16), nullable=True)
    direction = Column(String(10), nullable=True)  # inbound|outbound
    origin = Column(String(8), nullable=True)
    dest = Column(String(8), nullable=True)
    cargo_type = Column(String(128), nullable=True)
    cargo_weight_lbs = Column(Float, nullable=True)
    takeoff_hhmm = Column(String(4), nullable=True)
    eta_hhmm = Column(String(4), nullable=True)
    is_ramp_entry = Column(Integer, nullable=False, default=0)
    complete = Column(Integer, nullable=False, default=0)
    remarks = Column(Text, nullable=True)
    first_seen_at = Column(DateTime, nullable=False, default=datetime.utcnow)
    last_seen_at = Column(DateTime, nullable=False, default=datetime.utcnow)

    station = relationship("Station", back_populates="flights")
    __table_args__ = (
        Index("ix_flights_origin_dest_dir", "origin", "dest", "direction"),
        Index("ix_flights_complete_seen", "complete", "last_seen_at"),
        Index("ix_flights_station_aoct", "station_id", "aoct_flight_id"),
    )

class IngestLog(Base):
    __tablename__ = "ingest_log"
    id = Column(Integer, primary_key=True)
    station_id = Column(Integer, ForeignKey("stations.id"), nullable=False)
    received_at = Column(DateTime, nullable=False, default=datetime.utcnow)
    status = Column(String(16), nullable=False)  # accepted|rejected
    error = Column(Text, nullable=True)
    raw = Column(Text, nullable=True)

class Airport(Base):
    __tablename__ = "airports"
    code = Column(String(8), primary_key=True)  # ICAO/IATA/FAA
    lat = Column(Float, nullable=False)
    lon = Column(Float, nullable=False)
    __table_args__ = (Index("ix_airports_code", "code"),)

===== ./netops/routes/__init__.py =====
# netops/routes/__init__.py
# empty package marker

===== ./netops/routes/api.py =====
# netops/routes/api.py
from __future__ import annotations
from datetime import datetime, timedelta, timezone
from typing import Dict, Tuple
from flask import Blueprint, jsonify, request, abort, current_app
from sqlalchemy import func, select, and_, or_, text
from sqlalchemy.exc import IntegrityError
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

from ..db import SessionLocal
from ..models import Station, Snapshot, Flow, Flight, IngestLog, Airport
from ..schemas import LoginRequest, TokenResponse, IngestSnapshot
from ..auth import verify_password, issue_token, require_bearer
from ..config import config

api = Blueprint("api", __name__, url_prefix="/api")
# Create the limiter here; app binding happens in app.py via limiter.init_app(app)
limiter: Limiter = Limiter(key_func=get_remote_address)

def _now_utc() -> datetime:
    return datetime.now(timezone.utc)

@api.post("/login")
@limiter.limit(lambda: config.LOGIN_RATE)
def login():
    data = LoginRequest.parse_obj(request.get_json(force=True, silent=False))
    with SessionLocal() as s:
        st = s.execute(select(Station).where(Station.name == data.station)).scalar_one_or_none()
        if not st or not verify_password(st.password_hash, data.password):
            abort(401, description="Invalid station or password")
        token = issue_token(st.id, st.token_salt or "")
        st.last_seen_at = _now_utc()
        s.commit()
        return jsonify(TokenResponse(token=token).dict())

@api.get("/airports")
def list_airports():
    with SessionLocal() as s:
        rows = s.execute(select(Airport)).scalars().all()
        return jsonify([{"code": a.code, "lat": a.lat, "lon": a.lon} for a in rows])

@api.post("/airports")
def upsert_airport():
    # Admin gate (simple shared secret via ADMIN_PASSWORD header)
    admin = request.headers.get("X-Admin-Password", "")
    if config.ADMIN_PASSWORD and admin != config.ADMIN_PASSWORD:
        abort(403, description="Forbidden")
    js = request.get_json(force=True)
    code = (js.get("code") or "").strip().upper()
    lat = float(js.get("lat"))
    lon = float(js.get("lon"))
    if not code:
        abort(400, description="code required")
    with SessionLocal() as s:
        a = s.get(Airport, code)
        if not a:
            a = Airport(code=code, lat=lat, lon=lon)
            s.add(a)
        else:
            a.lat, a.lon = lat, lon
        s.commit()
        return jsonify({"ok": True})

@api.post("/ingest")
@limiter.limit(lambda: config.INGEST_RATE)
def ingest():
    station_id, _claims = require_bearer()
    payload = IngestSnapshot.parse_obj(request.get_json(force=True, silent=False))

    with SessionLocal() as s:
        st = s.get(Station, station_id)
        if not st or st.name != payload.station:
            abort(401, description="Token/station mismatch")

        # Update station last-seen + origin info
        st.last_seen_at = _now_utc()
        if payload.default_origin:
            st.last_default_origin = payload.default_origin.strip().upper()
        if payload.origin_coords:
            st.last_origin_lat = payload.origin_coords.lat
            st.last_origin_lon = payload.origin_coords.lon
            if payload.default_origin:
                # upsert airport for the default origin
                code = payload.default_origin.strip().upper()
                a = s.get(Airport, code)
                if not a:
                    s.add(Airport(code=code, lat=payload.origin_coords.lat, lon=payload.origin_coords.lon))
                else:
                    a.lat, a.lon = payload.origin_coords.lat, payload.origin_coords.lon

        # Snapshot de-dupe
        gen_at = payload.generated_at if payload.generated_at.tzinfo else payload.generated_at.replace(tzinfo=timezone.utc)
        snap = s.execute(
            select(Snapshot).where(
                Snapshot.station_id == station_id,
                Snapshot.generated_at == gen_at
            )
        ).scalar_one_or_none()

        if not snap:
            snap = Snapshot(
                station_id=station_id,
                generated_at=gen_at,
                window_hours=int(payload.window_hours or 24),
                inventory_last_update=payload.inventory_last_update or None
            )
            s.add(snap)
            s.flush()  # get id

        # Replace flows for this snapshot (idempotent)
        s.query(Flow).filter(Flow.snapshot_id == snap.id).delete(synchronize_session=False)
        for fr in payload.flows:
            s.add(Flow(
                snapshot_id=snap.id,
                origin=fr.origin.strip().upper(),
                dest=fr.dest.strip().upper(),
                direction=fr.direction,
                legs=int(fr.legs or 0),
                weight_lbs=float(fr.weight_lbs or 0.0),
            ))

        # Upsert manifests into flights (last state wins)
        for mf in payload.manifests:
            aoct_id = None
            if mf.flight_id is not None:
                aoct_id = int(mf.flight_id)
            # Preferred key: flight_code
            rec = None
            if mf.flight_code:
                rec = s.execute(select(Flight).where(Flight.flight_code == mf.flight_code)).scalar_one_or_none()
            if not rec and aoct_id is not None:
                rec = s.execute(select(Flight).where(Flight.station_id == station_id, Flight.aoct_flight_id == aoct_id)).scalar_one_or_none()
            if not rec and (mf.tail and mf.origin and mf.dest and mf.takeoff_hhmm):
                rec = s.execute(select(Flight).where(
                    Flight.station_id == station_id,
                    Flight.tail == mf.tail.strip().upper(),
                    Flight.origin == mf.origin.strip().upper(),
                    Flight.dest == mf.dest.strip().upper(),
                    Flight.takeoff_hhmm == mf.takeoff_hhmm.zfill(4),
                    Flight.complete == 0
                ).order_by(Flight.last_seen_at.desc())).scalar_one_or_none()

            if not rec:
                rec = Flight(station_id=station_id, first_seen_at=_now_utc())
                s.add(rec)

            # Assign/overwrite fields
            rec.aoct_flight_id = aoct_id if aoct_id is not None else rec.aoct_flight_id
            rec.flight_code = mf.flight_code or rec.flight_code
            rec.tail = (mf.tail or rec.tail or "").upper() or None
            rec.direction = mf.direction or rec.direction
            rec.origin = (mf.origin or rec.origin or "").upper() or None
            rec.dest = (mf.dest or rec.dest or "").upper() or None
            rec.cargo_type = mf.cargo_type or rec.cargo_type
            rec.cargo_weight_lbs = mf.cargo_weight_lbs if mf.cargo_weight_lbs is not None else rec.cargo_weight_lbs
            rec.takeoff_hhmm = mf.takeoff_hhmm or rec.takeoff_hhmm
            rec.eta_hhmm = mf.eta_hhmm or rec.eta_hhmm
            rec.is_ramp_entry = int(mf.is_ramp_entry or rec.is_ramp_entry or 0)
            rec.complete = int(mf.complete or rec.complete or 0)
            rec.remarks = mf.remarks or rec.remarks
            rec.last_seen_at = mf.updated_at or _now_utc()

        # Log ingest
        s.add(IngestLog(station_id=station_id, status="accepted", raw=None))
        s.commit()
        return jsonify({"ok": True})

@api.get("/flows")
def get_flows():
    q = request.args
    direction = q.get("direction", "all").lower()
    origin = (q.get("origin") or "").strip().upper()
    dest = (q.get("dest") or "").strip().upper()
    hours = q.get("hours")
    since = q.get("since")
    until = q.get("until")

    now = _now_utc()
    if hours and (since or until):
        abort(400, description="Use either hours or since/until")

    if hours:
        try:
            span = float(hours)
        except ValueError:
            abort(400, description="Invalid hours")
        start = now - timedelta(hours=span)
        end = now
    else:
        # parse since/until or default 24h
        def parse_iso(s: str) -> datetime:
            dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
        start = parse_iso(since) if since else now - timedelta(hours=24)
        end = parse_iso(until) if until else now

    with SessionLocal() as s:
        Snap = Snapshot
        Fl = Flow
        where = [Snap.generated_at >= start, Snap.generated_at <= end]
        if direction in ("inbound", "outbound"):
            where.append(Fl.direction == direction)
        if origin:
            where.append(Fl.origin == origin)
        if dest:
            where.append(Fl.dest == dest)

        rows = s.execute(
            select(
                Fl.origin, Fl.dest, Fl.direction,
                func.sum(Fl.legs), func.sum(Fl.weight_lbs)
            ).join(Snap, Fl.snapshot_id == Snap.id).where(and_(*where)).group_by(
                Fl.origin, Fl.dest, Fl.direction
            )
        ).all()

        data = [
            {"origin": o, "dest": d, "direction": dr, "legs": int(legs or 0), "weight_lbs": float(w or 0.0)}
            for (o, d, dr, legs, w) in rows
        ]
        return jsonify(data)

@api.get("/stations")
def get_stations():
    with SessionLocal() as s:
        sts = s.execute(select(Station)).scalars().all()
        return jsonify([
            {
                "name": st.name,
                "last_seen_at": st.last_seen_at.isoformat() if st.last_seen_at else None,
                "last_default_origin": st.last_default_origin,
                "last_origin_lat": st.last_origin_lat,
                "last_origin_lon": st.last_origin_lon,
            } for st in sts
        ])

@api.get("/stations/<name>/flights")
def get_station_flights(name: str):
    complete = request.args.get("complete", "open").lower()
    since = request.args.get("since")
    with SessionLocal() as s:
        st = s.execute(select(Station).where(Station.name == name)).scalar_one_or_none()
        if not st:
            abort(404, description="Station not found")
        q = select(Flight).where(Flight.station_id == st.id)
        if complete == "open" or complete == "0":
            q = q.where(Flight.complete == 0)
        elif complete == "1" or complete == "true":
            q = q.where(Flight.complete == 1)
        if since:
            try:
                dt = datetime.fromisoformat(since.replace("Z","+00:00"))
            except Exception:
                abort(400, description="Invalid since")
            q = q.where(Flight.last_seen_at >= dt)
        q = q.order_by(Flight.last_seen_at.desc())
        rows = s.execute(q).scalars().all()
        return jsonify([{
            "flight_code": r.flight_code,
            "tail": r.tail,
            "direction": r.direction,
            "origin": r.origin,
            "dest": r.dest,
            "cargo_type": r.cargo_type,
            "cargo_weight_lbs": r.cargo_weight_lbs,
            "takeoff_hhmm": r.takeoff_hhmm,
            "eta_hhmm": r.eta_hhmm,
            "is_ramp_entry": r.is_ramp_entry,
            "complete": r.complete,
            "remarks": r.remarks,
            "last_seen_at": r.last_seen_at.isoformat(),
        } for r in rows])

===== ./netops/routes/pages.py =====
# netops/routes/pages.py
from __future__ import annotations
from flask import Blueprint, render_template, request, redirect, url_for, session
from ..config import config

pages = Blueprint("pages", __name__)

@pages.get("/")
def index():
    return render_template("index.html")

@pages.get("/stations")
def stations():
    return render_template("stations.html")

@pages.get("/stations/<name>")
def station_detail(name: str):
    return render_template("station_detail.html", name=name)

@pages.get("/login")
def ui_login_form():
    # Optional simple UI gate
    return render_template("ui_login.html")

@pages.post("/login")
def ui_login():
    pw = request.form.get("password","")
    if config.ADMIN_PASSWORD and pw == config.ADMIN_PASSWORD:
        session["ui_admin"] = True
        return redirect(url_for("pages.index"))
    return redirect(url_for("pages.ui_login_form"))

===== ./netops/schemas.py =====
# netops/schemas.py
from __future__ import annotations
from typing import List, Optional, Literal
from datetime import datetime
from pydantic import BaseModel, Field, validator

Direction = Literal["inbound", "outbound"]

class LoginRequest(BaseModel):
    station: str
    password: str

class TokenResponse(BaseModel):
    token: str

class OriginCoords(BaseModel):
    lat: float
    lon: float

class FlowRow(BaseModel):
    origin: str
    dest: str
    direction: Direction
    legs: int = 0
    weight_lbs: float = 0.0

class ManifestRow(BaseModel):
    flight_id: Optional[int] = Field(None, alias="flight_id")
    flight_code: Optional[str] = None
    tail: Optional[str] = None
    direction: Optional[Direction] = None
    origin: Optional[str] = None
    dest: Optional[str] = None
    cargo_type: Optional[str] = None
    cargo_weight_lbs: Optional[float] = None
    remarks: Optional[str] = None
    takeoff_hhmm: Optional[str] = None
    eta_hhmm: Optional[str] = None
    is_ramp_entry: Optional[int] = 0
    complete: Optional[int] = 0
    updated_at: Optional[datetime] = None
    aoct_flight_id: Optional[int] = None  # alias; will map from flight_id if needed

    @validator("takeoff_hhmm", "eta_hhmm")
    def _hhmm(cls, v):
        if v is None or v == "":
            return v
        v = v.strip()
        if not (len(v) in (3,4) and v.isdigit()):
            raise ValueError("HHMM must be 3–4 digits")
        return v.zfill(4)

class IngestSnapshot(BaseModel):
    station: str
    generated_at: datetime
    default_origin: Optional[str] = None
    origin_coords: Optional[OriginCoords] = None
    inventory_last_update: Optional[str] = None
    window_hours: int = 24
    flows: List[FlowRow] = Field(default_factory=list)
    manifests: List[ManifestRow] = Field(default_factory=list)

===== ./requirements.txt =====
# requirements.txt
flask==3.0.2
waitress==3.0.0
python-dateutil==2.9.0.post0
SQLAlchemy==2.0.32
alembic==1.13.2
pydantic==1.10.15
PyJWT==2.9.0
argon2-cffi==23.1.0
flask-limiter==3.8.0
flask-cors==4.0.1

===== ./static/css/site.css =====
/* static/css/site.css */
:root { --bg:#0b0d10; --fg:#f2f5f7; --muted:#9aa4af; --accent:#60a5fa; --card:#14181c; }
*{box-sizing:border-box}
body{margin:0;background:var(--bg);color:var(--fg);font:14px/1.4 system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, "Helvetica Neue", Arial}
a{color:var(--accent);text-decoration:none}
.topbar{display:flex;gap:24px;align-items:center;padding:10px 16px;background:#0f1317;border-bottom:1px solid #1e242b}
.brand{font-weight:700}
.container{padding:16px}
#map{height:70vh;border:1px solid #222;border-radius:8px;margin-top:8px}
.controls{display:flex;gap:10px;align-items:center;margin-bottom:8px}
.tbl{width:100%;border-collapse:collapse;background:var(--card);border-radius:8px;overflow:hidden}
.tbl th,.tbl td{padding:8px 10px;border-bottom:1px solid #222}
.tbl th{background:#11161b;text-align:left}
.foot{padding:10px 16px;color:var(--muted);border-top:1px solid #1e242b}
.login-form{max-width:320px;background:var(--card);padding:16px;border:1px solid #1f2a37;border-radius:8px}
.login-form input{width:100%;padding:8px;margin-top:6px;margin-bottom:10px;background:#0f141a;border:1px solid #1f2a37;color:var(--fg);border-radius:6px}
button{background:var(--accent);color:#001b3a;border:0;padding:8px 12px;border-radius:6px;cursor:pointer}

===== ./static/js/map.js =====
// static/js/map.js
let map, airports = new Map(), polylines = [];

function clearLines(){
  for(const pl of polylines){ pl.remove(); }
  polylines = [];
}

function lineColor(direction){
  return direction === 'inbound' ? '#34d399' : '#60a5fa';
}

function widthFor(weight){
  if (!weight || weight <= 0) return 1;
  // 1..8px range (log-ish)
  return Math.max(1, Math.min(8, Math.log10(1+weight/100)));
}

async function ensureAirports(){
  if (airports.size) return;
  const r = await fetch('/api/airports');
  const rows = await r.json();
  for (const a of rows){ airports.set(a.code.toUpperCase(), [a.lat, a.lon]); }
}

function drawFlows(rows){
  clearLines();
  for (const r of rows){
    const A = airports.get(r.origin?.toUpperCase());
    const B = airports.get(r.dest?.toUpperCase());
    if (!A || !B) continue; // need both endpoints
    const pl = L.polyline([A, B], {weight: widthFor(r.weight_lbs), color: lineColor(r.direction)});
    pl.bindTooltip(`${r.origin} → ${r.dest} (${r.direction})\nlegs: ${r.legs}, weight: ${r.weight_lbs.toFixed(1)} lbs`);
    pl.addTo(map);
    polylines.push(pl);
  }
}

async function refresh(){
  await ensureAirports();
  const hours = document.getElementById('hours').value;
  const direction = document.getElementById('direction').value;
  const url = new URL('/api/flows', window.location.origin);
  url.searchParams.set('hours', hours);
  url.searchParams.set('direction', direction);
  const r = await fetch(url.toString());
  const rows = await r.json();
  drawFlows(rows);

  // simple table
  const div = document.getElementById('flows-table');
  div.innerHTML = '<table class="tbl"><thead><tr><th>Origin</th><th>Dest</th><th>Dir</th><th>Legs</th><th>Weight (lbs)</th></tr></thead><tbody></tbody></table>';
  const tb = div.querySelector('tbody');
  for (const x of rows){
    const tr = document.createElement('tr');
    tr.innerHTML = `<td>${x.origin}</td><td>${x.dest}</td><td>${x.direction}</td><td>${x.legs}</td><td>${x.weight_lbs.toFixed(1)}</td>`;
    tb.appendChild(tr);
  }
}

window.addEventListener('DOMContentLoaded', async () => {
  map = L.map('map').setView([47.6062, -122.3321], 7);
  L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {
    attribution: '&copy; OpenStreetMap',
    maxZoom: 12
  }).addTo(map);

  document.getElementById('refresh').addEventListener('click', refresh);
  refresh();
});

===== ./templates/base.html =====
<!-- templates/base.html -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>NetOpsTool</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="{{ url_for('static', filename='css/site.css') }}" rel="stylesheet">
  <link rel="stylesheet" href="https://unpkg.com/leaflet@1.9.4/dist/leaflet.css"
        integrity="sha256-p4NxAoJBhIIN+hmNHrzRCf9tD/miZyoHS5obTRR9BMY=" crossorigin=""/>
  <script src="https://unpkg.com/leaflet@1.9.4/dist/leaflet.js"
          integrity="sha256-20nQCchB9co0qIjJZRGuk2/Z9VM+kNiyxNV1lvTlZBo="
          crossorigin=""></script>
</head>
<body>
<header class="topbar">
  <div class="brand">NetOpsTool</div>
  <nav>
    <a href="{{ url_for('pages.index') }}">Map</a>
    <a href="{{ url_for('pages.stations') }}">Stations</a>
  </nav>
</header>
<main class="container">
  {% block content %}{% endblock %}
</main>
<footer class="foot">
  <span>&copy; {{ (namespace().year if namespace else none) or  (config.get('current_year') if config else '') or '' }}</span>
</footer>
</body>
</html>

===== ./templates/index.html =====
<!-- templates/index.html -->
{% extends "base.html" %}
{% block content %}
<h2>Cargo Flows</h2>
<div class="controls">
  <label>Window:
    <select id="hours">
      <option value="6">6h</option>
      <option value="24" selected>24h</option>
      <option value="72">72h</option>
    </select>
  </label>
  <label>Direction:
    <select id="direction">
      <option value="all" selected>All</option>
      <option value="inbound">Inbound</option>
      <option value="outbound">Outbound</option>
    </select>
  </label>
  <button id="refresh">Refresh</button>
</div>
<div id="map"></div>
<div id="flows-table"></div>
<script src="{{ url_for('static', filename='js/map.js') }}"></script>
{% endblock %}

===== ./templates/station_detail.html =====
<!-- templates/station_detail.html -->
{% extends "base.html" %}
{% block content %}
<h2>Station: {{ name }}</h2>
<table class="tbl" id="flights-table">
  <thead>
    <tr>
      <th>Last Seen</th><th>Code</th><th>Tail</th><th>Dir</th><th>Origin</th><th>Dest</th>
      <th>Cargo</th><th>Weight (lbs)</th><th>T/O</th><th>ETA</th><th>Ramp</th><th>Done</th><th>Remarks</th>
    </tr>
  </thead>
  <tbody></tbody>
</table>
<script>
async function loadFlights(){
  const r = await fetch(`/api/stations/{{ name|tojson|safe }}/flights?complete=all`);
  const rows = await r.json();
  const tb = document.querySelector('#flights-table tbody');
  tb.innerHTML = '';
  for (const f of rows){
    const tr = document.createElement('tr');
    tr.innerHTML = `
      <td>${f.last_seen_at}</td>
      <td>${f.flight_code||'—'}</td>
      <td>${f.tail||'—'}</td>
      <td>${f.direction||'—'}</td>
      <td>${f.origin||'—'}</td>
      <td>${f.dest||'—'}</td>
      <td>${f.cargo_type||'—'}</td>
      <td>${(f.cargo_weight_lbs??'—')}</td>
      <td>${f.takeoff_hhmm||'—'}</td>
      <td>${f.eta_hhmm||'—'}</td>
      <td>${f.is_ramp_entry? '✓':'—'}</td>
      <td>${f.complete? '✓':'—'}</td>
      <td>${f.remarks||''}</td>
    `;
    tb.appendChild(tr);
  }
}
loadFlights();
</script>
{% endblock %}

===== ./templates/stations.html =====
<!-- templates/stations.html -->
{% extends "base.html" %}
{% block content %}
<h2>Stations</h2>
<table class="tbl" id="stations-table">
  <thead><tr><th>Name</th><th>Last Seen</th><th>Default Origin</th><th>Coords</th></tr></thead>
  <tbody></tbody>
</table>
<script>
async function loadStations(){
  const r = await fetch('/api/stations');
  const rows = await r.json();
  const tb = document.querySelector('#stations-table tbody');
  tb.innerHTML = '';
  for (const st of rows){
    const tr = document.createElement('tr');
    const link = `<a href="/stations/${encodeURIComponent(st.name)}">${st.name}</a>`;
    const coords = (st.last_origin_lat!=null && st.last_origin_lon!=null)
      ? `${st.last_origin_lat.toFixed(5)}, ${st.last_origin_lon.toFixed(5)}`
      : '—';
    tr.innerHTML = `<td>${link}</td><td>${st.last_seen_at||'—'}</td><td>${st.last_default_origin||'—'}</td><td>${coords}</td>`;
    tb.appendChild(tr);
  }
}
loadStations();
</script>
{% endblock %}

===== ./templates/ui_login.html =====
<!-- templates/ui_login.html -->
{% extends "base.html" %}
{% block content %}
<h2>Admin Login</h2>
<form method="post" action="/login" class="login-form">
  <label>Password <input type="password" name="password" required></label>
  <button type="submit">Login</button>
</form>
{% endblock %}
